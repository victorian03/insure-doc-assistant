# app.py  â€” Insure Doc Assistant (RAG on PDFs) â€“ bundled samples

from pathlib import Path
from glob import glob
import shutil
import streamlit as st

from src.config import Settings
from src.utils import ensure_dirs, Timer

from src.vectorstore import VectorStore
from src.retriever import Retriever
from src.rag_chain import RAGChain

st.set_page_config(page_title="Insure Doc Assistant", page_icon="ğŸ“„", layout="wide")

# --- Paths & setup
BASE_DIR = Path.cwd()
DATA_DIR = BASE_DIR / "data"
INDEX_DIR = DATA_DIR / "index"
OUTPUT_DIR = DATA_DIR / "output"
ensure_dirs(INDEX_DIR, OUTPUT_DIR)


def sample_pdfs():
    """Toate PDF-urile din data/samples/ (bundled cu proiectul)."""
    samples_dir = DATA_DIR / "samples"
    samples_dir.mkdir(parents=True, exist_ok=True)
    return sorted(glob(str(samples_dir / "*.pdf")))


# --- Config din .env
settings = Settings()

# --- Page header
st.title("ğŸ“„ Insure Doc Assistant â€“ RAG on PDFs")
st.caption("PDF-urile din `data/samples/` se indexeazÄƒ automat (bundled). Apoi poÈ›i Ã®ntreba È™i primeÈ™ti citÄƒri de surse.")

with st.sidebar:
    st.header("âš™ï¸ Config")
    st.write(f"Embeddings: **{settings.EMBEDDING_PROVIDER}**")
    st.write(f"Model: **{settings.EMBEDDING_MODEL}**")
    st.write(f"LLM: **{settings.LLM_PROVIDER}**")
    TOP_K = settings.TOP_K
    MAX_CONTEXT_CHARS = settings.MAX_CONTEXT_CHARS

# --- Vector store + auto-index la pornire (doar dacÄƒ nu existÄƒ index)
vs = VectorStore(index_dir=INDEX_DIR)
if not vs.exists():
    bundled = sample_pdfs()
    if bundled:
        with st.spinner(f"Building first index from bundled PDFs ({len(bundled)} docs)â€¦"):
            docs = ingest_pdfs(bundled, default_meta={"doc_type": "Bundled"})
            vs.build_or_update(docs)
        st.success(f"Bundled PDFs indexed: {len(docs)} chunks from {len(bundled)} files.")
    else:
        st.info("Nu am gÄƒsit PDF-uri Ã®n `data/samples/`. AdaugÄƒ fiÈ™iere acolo sau foloseÈ™te upload (dacÄƒ pÄƒstrezi secÈ›iunea).")

# --- Optional: buton de rebuild din samples (fÄƒrÄƒ upload)
st.markdown("### ğŸ“¦ Bundled samples")
st.write("IndexeazÄƒ/reecreeazÄƒ indexul direct din PDF-urile incluse Ã®n proiect (`data/samples/`).")
if st.button("Rebuild index from data/samples/ (no upload)"):
    bundled = sample_pdfs()
    if not bundled:
        st.warning("Nu existÄƒ PDF-uri Ã®n `data/samples/`.")
    else:
        with st.spinner(f"Rebuilding index from {len(bundled)} bundled PDFsâ€¦"):
            # È™terge indexul vechi pentru a evita dublarea
            shutil.rmtree(INDEX_DIR, ignore_errors=True)
            ensure_dirs(INDEX_DIR)
            _vs = VectorStore(index_dir=INDEX_DIR)
            docs = ingest_pdfs(bundled, default_meta={"doc_type": "Bundled"})
            _vs.build_or_update(docs)
        st.success(f"Rebuilt. Indexed {len(docs)} chunks from {len(bundled)} files.")

# --- Q&A section
st.markdown("### ğŸ” Ask a question")
retriever = Retriever(VectorStore(index_dir=INDEX_DIR))
rag = RAGChain(settings=settings)

q_col, k_col, rerank_col = st.columns([6, 1, 2])
with q_col:
    question = st.text_input("Your question (e.g., 'Care este perioada de graÈ›ie?')")
with k_col:
    top_k = st.number_input("Top-K", 1, 20, value=TOP_K)
with rerank_col:
    do_rerank = st.checkbox("Re-rank (lexical + semantic)", value=True)

if st.button("Answer"):
    if not retriever.vs.exists():
        st.error("Nu existÄƒ niciun index. AsigurÄƒ-te cÄƒ sunt PDF-uri Ã®n `data/samples/` È™i apasÄƒ Rebuild.")
    elif not question.strip():
        st.wa
